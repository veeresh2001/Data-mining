{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbb515-1143-42f5-a096-69ab982fc1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cd67ec-241c-4d11-96f3-00ba2a7e3b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parkinsons Telemonitoring Data Set  \n",
    "\n",
    "#Abstract: Oxford Parkinson's Disease Telemonitoring Dataset\n",
    "\n",
    "#============================================================\n",
    "\n",
    "#Data Set Characteristics:  Multivariate\n",
    "#Attribute Characteristics:  Integer, Real\n",
    "#Associated Tasks:  Regression\n",
    "#Number of Instances:  5875\n",
    "#Number of Attributes:  26\n",
    "#Area:  Life\n",
    "#Date Donated:  2009-10-29\n",
    "\n",
    "#============================================================\n",
    "\n",
    "#SOURCE:\n",
    "\n",
    "#The dataset was created by Athanasios Tsanas (tsanasthanasis '@' gmail.com) \n",
    "#and Max Little (littlem '@' physics.ox.ac.uk) of the University of Oxford, in \n",
    "#collaboration with 10 medical centers in the US and Intel Corporation who \n",
    "#developed the telemonitoring device to record the speech signals. The \n",
    "#original study used a range of linear and nonlinear regression methods to \n",
    "#predict the clinicians Parkinsons disease symptom score on the UPDRS scale.\n",
    "\n",
    "\n",
    "#============================================================\n",
    "\n",
    "#DATA SET INFORMATION:\n",
    "\n",
    "#This dataset is composed of a range of biomedical voice measurements from 42 \n",
    "#people with early-stage Parkinson's disease recruited to a six-month trial of \n",
    "#a telemonitoring device for remote symptom progression monitoring. The \n",
    "#recordings were automatically captured in the patient's homes.\n",
    "\n",
    "#Columns in the table contain subject number, subject age, subject gender, \n",
    "#time interval from baseline recruitment date, motor UPDRS, total UPDRS, and \n",
    "#16 biomedical voice measures. Each row corresponds to one of 5,875 voice \n",
    "#recording from these individuals. The main aim of the data is to predict the \n",
    "#motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 \n",
    "#voice measures.\n",
    "\n",
    "#The data is in ASCII CSV format. The rows of the CSV file contain an instance \n",
    "#corresponding to one voice recording. There are around 200 recordings per \n",
    "#patient, the subject number of the patient is identified in the first column. \n",
    "#For further information or to pass on comments, please contact Athanasios \n",
    "#Tsanas (tsanasthanasis '@' gmail.com) or Max Little (littlem '@' \n",
    "#physics.ox.ac.uk).\n",
    "\n",
    "#Further details are contained in the following reference -- if you use this \n",
    "#dataset, please cite:\n",
    "#Athanasios Tsanas, Max A. Little, Patrick E. McSharry, Lorraine O. Ramig (2009),\n",
    "#'Accurate telemonitoring of Parkinson.s disease progression by non-invasive speech tests',\n",
    "#IEEE Transactions on Biomedical Engineering (to appear).\n",
    "\n",
    "#Further details about the biomedical voice measures can be found in:\n",
    "#Max A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2009),\n",
    "#'Suitability of dysphonia measurements for telemonitoring of Parkinsons disease',\n",
    "#IEEE Transactions on Biomedical Engineering, 56(4):1015-1022 \n",
    "\n",
    " \n",
    "#===========================================================\n",
    "\n",
    "#ATTRIBUTE INFORMATION:\n",
    "\n",
    "#subject# - Integer that uniquely identifies each subject\n",
    "#age - Subject age\n",
    "#sex - Subject gender '0' - male, '1' - female\n",
    "#test_time - Time since recruitment into the trial. The integer part is the \n",
    "#number of days since recruitment.\n",
    "#motor_UPDRS - Clinicians motor UPDRS score, linearly interpolated\n",
    "#total_UPDRS - Clinicians total UPDRS score, linearly interpolated\n",
    "#Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of \n",
    "#variation in fundamental frequency\n",
    "#Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - \n",
    "#Several measures of variation in amplitude\n",
    "#NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "#RPDE - A nonlinear dynamical complexity measure\n",
    "#DFA - Signal fractal scaling exponent\n",
    "#PPE - A nonlinear measure of fundamental frequency variation \n",
    "\n",
    "\n",
    "#===========================================================\n",
    "\n",
    "#RELEVANT PAPERS:\n",
    "\n",
    "#Little MA, McSharry PE, Hunter EJ, Ramig LO (2009),\n",
    "#'Suitability of dysphonia measurements for telemonitoring of Parkinsons disease',\n",
    "#IEEE Transactions on Biomedical Engineering, 56(4):1015-1022\n",
    "\n",
    "#Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM.\n",
    "#'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection',\n",
    "#BioMedical Engineering OnLine 2007, 6:23 (26 June 2007) \n",
    "\n",
    "#===========================================================\n",
    "\n",
    "#CITATION REQUEST:\n",
    "\n",
    "#If you use this dataset, please cite the following paper:\n",
    "#A Tsanas, MA Little, PE McSharry, LO Ramig (2009)\n",
    "#'Accurate telemonitoring of Parkinsons disease progression by non-invasive speech tests',\n",
    "#IEEE Transactions on Biomedical Engineering (to appear). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bb9121-8a81-4f43-99fc-8aff0eb62272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, fpmax, fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00bcafc8-e334-4b2e-9eb5-7afe6853df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load raw data file\n",
    "dataFileA=pd.read_csv(\"parkinsons_updrs.data\") #found file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f33198-98cb-489a-94c5-64032253457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileA_np_raw = np.array(dataFileA)\n",
    "dataFileA_np = dataFileA_np_raw[:,4:]\n",
    "\n",
    "normalizedA = (dataFileA_np-np.min(dataFileA_np))/(np.max(dataFileA_np)-np.min(dataFileA_np))\n",
    "\n",
    "#note that normalizedA isnt meaningful for the first 3 columns\n",
    "normalizedA_data = normalizedA[:,3:]\n",
    "normalizedA_data = normalizedA[:,:normalizedA_data.shape[1]-3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d626db61-e9ce-4f8e-96bb-0ad6c62a8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAYS OF ENCODING THE DATA\n",
    "#\n",
    "# Equal size categories\n",
    "# Low (<0.2) , Medium-Low (>=0.2, <0.4), Medium (>=0.4, <0.6), Medium-High (>=0.6, <0.8), High(>=0.8)\n",
    "#\n",
    "# Normalized distribution based\n",
    "# Low (<0.024) , Medium-Low (>=0.024, <0.1583), Medium (>=0.1583, <0.8409), Medium-High (>=0.8409, <0.9806), High(>=0.9806)\n",
    "#\n",
    "# Extreme magnitudes\n",
    "# Outlier (<0.02 or >0.98), Different(<0.1583 or >0.8417), Central(>=0.1583 and <=0.8416)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cee6093-7c2a-4841-b91e-b63c78e1f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equal size categories\n",
    "# Low (<0.2) , Medium-Low (>=0.2, <0.4), Medium (>=0.4, <0.6), Medium-High (>=0.6, <0.8), High(>=0.8)\n",
    "dataAsEqualSize = [''] * normalizedA_data.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedA_data.shape[0]): \n",
    "    dataAsEqualSize[iter] = [''] * normalizedA_data.shape[1]\n",
    "    \n",
    "    for innerIter in range(0, normalizedA_data.shape[1]):\n",
    "        \n",
    "        if normalizedA_data[iter][innerIter] <= 0.2 :\n",
    "            dataAsEqualSize[iter][innerIter] = \"LOW\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.2 and normalizedA_data[iter][innerIter] <= 0.4:\n",
    "            dataAsEqualSize[iter][innerIter] = \"MEDLOW\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.4 and normalizedA_data[iter][innerIter] <= 0.6:\n",
    "            dataAsEqualSize[iter][innerIter] = \"MED\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.6 and normalizedA_data[iter][innerIter] <= 0.8:\n",
    "            dataAsEqualSize[iter][innerIter] = \"MEDHIGH\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] >= 0.8 :\n",
    "            dataAsEqualSize[iter][innerIter] = \"HIGH\" + str(innerIter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fec91b-5241-4203-9478-b4f02fceed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized distribution size categories\n",
    "# Low (<0.024) , Medium-Low (>=0.024, <0.1583), Medium (>=0.1583, <0.8409), Medium-High (>=0.8409, <0.9806), High(>=0.9806)\n",
    "normalDistribution = [''] * normalizedA_data.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedA_data.shape[0]): \n",
    "    normalDistribution[iter] = [''] * normalizedA_data.shape[1]\n",
    "    for innerIter in range(0, normalizedA_data.shape[1]):\n",
    "        if normalizedA_data[iter][innerIter] <= 0.024 :\n",
    "            normalDistribution[iter][innerIter] = \"LOW\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.024 and normalizedA_data[iter][innerIter] <= 0.1583:\n",
    "            normalDistribution[iter][innerIter] = \"MEDLOW\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.1583 and normalizedA_data[iter][innerIter] <= 0.8409:\n",
    "            normalDistribution[iter][innerIter] = \"MED\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] > 0.8409 and normalizedA_data[iter][innerIter] <= 0.9806:\n",
    "            normalDistribution[iter][innerIter] = \"MEDHIGH\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] >= 0.9806 :\n",
    "            normalDistribution[iter][innerIter] = \"HIGH\" + str(innerIter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20722e9-5b03-4232-a6ac-6e2f2bff85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extreme magnitude categories\n",
    "# Outlier (<0.02 or >0.98), Different(<0.1583 or >0.8417), Central(>=0.1583 and <=0.8416)\n",
    "extremeMagnitude = [''] * normalizedA_data.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedA_data.shape[0]): \n",
    "    extremeMagnitude[iter] = [''] * normalizedA_data.shape[1]\n",
    "    for innerIter in range(0, normalizedA_data.shape[1]):        \n",
    "        if normalizedA_data[iter][innerIter] <= 0.024 or normalizedA_data[iter][innerIter] >= 0.976:\n",
    "            extremeMagnitude[iter][innerIter] = \"EXTR\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] <= 0.1583 or normalizedA_data[iter][innerIter] >= 0.8417:\n",
    "            extremeMagnitude[iter][innerIter] = \"DIFF\" + str(innerIter)\n",
    "        else:\n",
    "            extremeMagnitude[iter][innerIter] = \"MED\" + str(innerIter)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff67634-6633-4395-93b2-25df039b14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW TO DO THE TRUTH DATA COLUMNS\n",
    "rawTruth = dataFileA_np_raw[:,4:6]\n",
    "normalizedTruth = (rawTruth-np.min(rawTruth))/(np.max(rawTruth)-np.min(rawTruth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4317d459-79c0-4afc-8b8c-e52fe489e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equal size categories\n",
    "# Low (<0.2) , Medium-Low (>=0.2, <0.4), Medium (>=0.4, <0.6), Medium-High (>=0.6, <0.8), High(>=0.8)\n",
    "normalizedTruthAsEqualSize = [''] * normalizedTruth.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedTruth.shape[0]): \n",
    "    normalizedTruthAsEqualSize[iter] = [''] * normalizedTruth.shape[1]\n",
    "\n",
    "    for innerIter in range(0, normalizedTruth.shape[1]):\n",
    "        \n",
    "        if normalizedTruth[iter][innerIter] <= 0.2 :\n",
    "\n",
    "            normalizedTruthAsEqualSize[iter][innerIter] = \"LOWT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.2 and normalizedTruth[iter][innerIter] <= 0.4:\n",
    "            normalizedTruthAsEqualSize[iter][innerIter] = \"MEDLOWT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.4 and normalizedTruth[iter][innerIter] <= 0.6:\n",
    "            normalizedTruthAsEqualSize[iter][innerIter] = \"MEDT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.6 and normalizedTruth[iter][innerIter] <= 0.8:\n",
    "            normalizedTruthAsEqualSize[iter][innerIter] = \"MEDHIGHT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] >= 0.8 :\n",
    "            normalizedTruthAsEqualSize[iter][innerIter] = \"HIGHT\" + str(innerIter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2da3a25-9e28-4970-b3da-d4c48cbc1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedTruthAsNormalDistribution = [''] * normalizedTruth.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedTruth.shape[0]): \n",
    "    normalizedTruthAsNormalDistribution[iter] = [''] * normalizedTruth.shape[1]\n",
    "\n",
    "    for innerIter in range(0, normalizedTruth.shape[1]):\n",
    "        \n",
    "        if normalizedTruth[iter][innerIter] <= 0.024 :\n",
    "\n",
    "            normalizedTruthAsNormalDistribution[iter][innerIter] = \"LOWT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.024 and normalizedTruth[iter][innerIter] <= 0.1583:\n",
    "            normalizedTruthAsNormalDistribution[iter][innerIter] = \"MEDLOWT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.1583 and normalizedTruth[iter][innerIter] <= 0.8409:\n",
    "            normalizedTruthAsNormalDistribution[iter][innerIter] = \"MEDT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] > 0.8409 and normalizedTruth[iter][innerIter] <= 0.9806:\n",
    "            normalizedTruthAsNormalDistribution[iter][innerIter] = \"MEDHIGHT\" + str(innerIter)\n",
    "        elif normalizedTruth[iter][innerIter] >= 0.9806 :\n",
    "            normalizedTruthAsNormalDistribution[iter][innerIter] = \"HIGHT\" + str(innerIter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c06ece7-9c92-415a-a49f-deb6c37b0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extreme magnitude categories\n",
    "# Outlier (<0.02 or >0.98), Different(<0.1583 or >0.8417), Central(>=0.1583 and <=0.8416)\n",
    "normalizedTruthAsExtremeMagnitude = [''] * normalizedTruth.shape[0]\n",
    "\n",
    "for iter in range(0, normalizedTruth.shape[0]): \n",
    "    normalizedTruthAsExtremeMagnitude[iter] = [''] * normalizedTruth.shape[1]\n",
    "    for innerIter in range(0, normalizedTruth.shape[1]):        \n",
    "        if normalizedA_data[iter][innerIter] <= 0.024 or normalizedTruth[iter][innerIter] >= 0.976:\n",
    "            normalizedTruthAsExtremeMagnitude[iter][innerIter] = \"EXTR\" + str(innerIter)\n",
    "        elif normalizedA_data[iter][innerIter] <= 0.1583 or normalizedTruth[iter][innerIter] >= 0.8417:\n",
    "            normalizedTruthAsExtremeMagnitude[iter][innerIter] = \"DIFF\" + str(innerIter)\n",
    "        else:\n",
    "            normalizedTruthAsExtremeMagnitude[iter][innerIter] = \"MED\" + str(innerIter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d24860-3ee1-425b-a17a-c1b7f4d6a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO NOW WE HAVE TWO SETS OF DATA, ONE IS THE MEASURED BY MACHINES AND ONE IS MEASURED BY HUMANS\n",
    "# EACH SET OF DATA IS ENCODED IN THREE WAYS:\n",
    "#\n",
    "# Equal size categories\n",
    "# Low (<0.2) , Medium-Low (>=0.2, <0.4), Medium (>=0.4, <0.6), Medium-High (>=0.6, <0.8), High(>=0.8)\n",
    "#\n",
    "# Normalized distribution based\n",
    "# Low (<0.024) , Medium-Low (>=0.024, <0.1583), Medium (>=0.1583, <0.8409), Medium-High (>=0.8409, <0.9806), High(>=0.9806)\n",
    "#\n",
    "# Extreme magnitudes\n",
    "# Outlier (<0.02 or >0.98), Different(<0.1583 or >0.8417), Central(>=0.1583 and <=0.8416)\n",
    "#\n",
    "\n",
    "#TRUTH (desired future purchase in the transaction model):\n",
    "#normalizedTruthAsEqualSize,    normalizedTruthAsNormalDistribution,   normalizedTruthAsExtremeMagnitude\n",
    "\n",
    "#MACHINES OBSERVED (items purchased in the transaction model):\n",
    "#dataAsEqualSize,    normalDistribution,      extremeMagnitude\n",
    "\n",
    "#ADDITIONAL DATA POINTS THAT CAN BE USED\n",
    "#Different frequency calculations (fpgrowth, fpmax, apriori)\n",
    "#min_support \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc42644a-7168-44ca-9639-84ba9cb5ed80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#EXAMPLES TAKEN FROM \n",
    "#https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/\n",
    "\n",
    "dataset = np.concatenate((normalizedTruthAsEqualSize,dataAsEqualSize), axis=1)\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df_max = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "frequent_itemsets_grow = fpgrowth(df, min_support=0.6)\n",
    "frequent_itemsets_ap = apriori(df, min_support=0.6)\n",
    "frequent_itemsets_max = fpmax(df_max, min_support=0.6)\n",
    "\n",
    "#print(frequent_itemsets_grow)\n",
    "#print(\"HERE\")\n",
    "#print(frequent_itemsets_ap)\n",
    "#print(\"HERE\")\n",
    "#print(frequent_itemsets_max)\n",
    "\n",
    "rules = association_rules(frequent_itemsets_grow, metric=\"lift\", min_threshold=1.2)\n",
    "print(rules)\n",
    "rules = association_rules(frequent_itemsets_grow, metric=\"confidence\", min_threshold=0.7)\n",
    "#print(rules)\n",
    "\n",
    "rules = association_rules(frequent_itemsets_ap, metric=\"lift\", min_threshold=1.2)\n",
    "#print(rules)\n",
    "rules = association_rules(frequent_itemsets_ap, metric=\"confidence\", min_threshold=0.7)\n",
    "#print(rules)\n",
    "\n",
    "rules = association_rules(frequent_itemsets_max, metric=\"lift\", min_threshold=1.2, support_only=True)\n",
    "#print(rules)\n",
    "rules = association_rules(frequent_itemsets_max, metric=\"confidence\", min_threshold=0.7, support_only=True)\n",
    "#print(rules)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b1eb6e-e38e-4a32-a304-7b76659a94d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
